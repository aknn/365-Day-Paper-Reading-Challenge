#+TITLE: 365-day-paper-reading-challenge
#+AUTHOR: happygirlzt
#+DATETIME: 2020-06-26 Fri

* To readers
You could fork this repo and start your own 365-day challenge on your branch. Let's study together!

* Schedule
I will read an article related to deep learning, reinforcement learning, natural language processing, and/or software engineering every day. This paper reading is more about a breadth reading. I do not want all my reading is limited to my research project. I hope I could keep pace with the latest research in AI/ML/DL/SE. So, in that case, the paper reading will be in *coarse-grained* manner.

I will try to summarize the key idea of the paper. Currently, I want my daily notes to follow the structure:
1. Problem
2. Method
3. Result
4. Future work

I hope I could keep it work up and improve my ability to read and write.

* Paper List
1. Day 1: How Bad Can a Bug Get? An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform
2. Day 2: Towards understanding bugs in an open source cloud management stack: An empirical study of OpenStack software bugs
3. Day 3: Is deep learning better than traditional approaches in tag recommendation for software information sites?
4. Day 4: CodeBERT: A Pre-Trained Model for Programming and Natural Languages]]
5. Day 5: Examining the Impact of Self-admitted Technical Debt on Software Quality
6. Day 6: Identifying self-admitted technical debt through code comment analysis with a contextualized vocabulary
7. Day 7: How Do Companies Collaborate in Open Source Ecosystems? An Empirical Study of OpenStack
8. Day 8: Companies' Participation in OSS Development - An Empirical Study of OpenStack
9. Day 9: Detecting and Quantifying Different Types of Self-Admitted Technical Debt
10. Day 10: What do Programmers Discuss about Deep Learning Frameworks
11. Day 11: Beyond the Code: Mining Self-Admitted Technical Debt in Issue Tracker Systems
12. Day 12: Software Engineering Challenges of Deep Learning
13. Day 13: code2vec: Learning Distributed Representations of Code
14. Day 14: What Do Programmers Discuss about Blockchain?
15. Day 15: Assessing the generalizability of code2vec token embeddings
16. Day 16: The impact factors on the performance of machine learning-based vulnerability detection: A comparative study
17. Day 17: Going Big: A Large-Scale Study on What Big Data Developers Ask
18. Day 18: What are developers talking about? An analysis of topics and trends in Stack Overflow
19. Day 19: Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping
20. Day 20: tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection
21. Day 21: Neural Topic Modeling with Bidirectional Adversarial Training
22. Day 22: SMART: Robust and Efficient Fine-Tuning for Pr-trained Natural Language Models through Principled Regularized Optimization
23. Day 23: Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis
24. Day 24: A Primer in BERTology: What we know about how BERT works
25. Day 25: What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study
26. Day 26: A Transformer-based Approach for Source Code Summarization
27. Day 27: A Survey on Contextual Embeddings
28. Day 28: TranS3: A Transformer-based Framework for Unifying Code Summarization and Code Search
29. Day 29: An Empirical Study on TensorFlow Program Bugs
30. Day 30: Graph Few-shot Learning via Knowledge Transfer
31. Day 31: Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding
32. Day 32: Simulee: Detecting CUDA Synchronization Bugs via Memory-Access Modeling
33. Day 33: Identifying experts in software libraries and frameworks among GitHub users
34. Day 34: DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference
35. Day 35: Table Search Using a Deep Contextualized Language Model
36. Day 36: An Analysis of BERT in Document Ranking
37. Day 37: A Pairwise Probe for Understanding BERT Fine-Tuning on Machine Reading Comprehension
38. Day 38: TRADER: Trace Divergence Analysis and Embedding Regulation for Debugging Recurrent Neural Networks
39. Day 39: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList
40. Day 40: Here We Go Again: Why Is It Difficult for Developers to Learn Another Programming Language?
41. Day 41: Deep Transfer Bug Localization
42. Day 42: Causal Testing: Understanding Defects’ Root Causes
43. Day 43: An Empirical Study on API Parameter Rules Hao
44. Day 44: Unblind Your Apps: Predicting Natural-Language Labels for Mobile GUI Components by Deep Learning
45. Day 45: Wireframe-based UI Design Search through Image Autoencoder
46. Day 46: Repairing Deep Neural Networks: Fix Patterns and Challenges
47. Day 47: Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks
48. Day 48: Understanding the Automated Parameter Optimization on Transfer Learning for CPDP: An Empirical Study
49. Day 49: CPC: Automatically Classifying and Propagating Natural Language Comments via Program Analysis
50. Day 50: Gang of Eight: A Defect Taxonomy for Infrastructure as Code Scripts
51. Day 51: Predictive Models in Software Engineering: Challenges and Opportunities
52. Day 52: Where should I comment my code? A dataset and model for predicting locations that need comments
53. Day 53: Better Code, Better Sharing: On the Need of Analyzing Jupyter Notebooks
54. Day 54: Assessing Practitioner Beliefs about Software Defect Prediction
55. Day 55: Skyline: Interactive In-Editor Computational Performance Profiling for Deep Neural Network Training
56. Day 56: Suggesting Natural Method Names to Check Name Consistencies
57. Day 57: Is Your Quantum Program Bug-Free?
58. Day 58: Efficient Generation of Error-Inducing Floating-Point Inputs via Symbolic Execution
59. Day 59: A Study on the Prevalence of Human Values in Software Engineering Publications, 2015 – 2018
60. Day 60: Pre-trained Models for Natural Language Processing: A Survey
61. Day 61: Contextual Word Representations: A Contextual Introduction
62. Day 62: Neurological Divide: An fMRI Study of Prose and CodeWriting
63. Day 63: Is Static Analysis Able to Identify Unnecessary Source Code?
64. Day 64: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
65. Day 65: A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects
66. Day 66: On the Generalizability of Neural Program Analyzers with respect to Semantic-Preserving Program Transformations
67. Day 67: Reformulating Queries for Duplicate Bug Report Detection
68. Day 68: Automatic Duplicate Bug Report Detection using Information Retrieval-based versus Machine Learning-based Approaches
69. Day 69: Train One Get One Free: Partially Supervised Neural Network for Bug Report Duplicate Detection and Clustering
70. Day 70: An HMM-Based Approach for Automatic Detection and Classification of Duplicate Bug Reports