* Duration
From 25 Aug 2020 to

* Content
1. [[#day-61-nlp][Day 61: Contextual Word Representations: A Contextual Introduction]]
2. [[#day-62-se][Day 62: Neurological Divide: An fMRI Study of Prose and CodeWriting]]
3. [[#day-63-se][Day 63: Is Static Analysis Able to Identify Unnecessary Source Code?]]
4. [[#day-64-nlp][Day 64: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations]]
5. [[#day-65-se][Day 65: A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects]]
6. [[#day-66-se][Day 66: On the Generalizability of Neural Program Analyzers with respect to Semantic-Preserving Program Transformations]]

* Day 61: NLP
- *Title*: Contextual Word Representations: A Contextual Introduction
- *Year*: 2020

The following content is referred from [1]
** Discrete words
a sequence of characters

each word type was given a unique (and more or less arbitrary) nonnegative inter value

*** Advantages
1. every word type was stored in the same amount of memory
2. array-based data structures could be used to index other information by word types

*** Disadvantages
the integers did not mean anything

The assignment might be arbitrary, alphabetical, or in the order word tokens

** Words vs Distributional Vectors: Context as Meaning
It's useful to first map each input word token to its vector, and then "feed" the word vectors into the neural network model, which performs a task like translation.

** Contextual word vectors
ELMo, which stands for "embeddings from language models" (Peters et al., 2018a), brought a powerful advance in the form ofword token vectors—i.e., vectors for words in context, or contextual word vectors—that are pretrained on large corpora.

A longstanding data-fitting problem in NLP is language modeling, which refers to predicting the next word given a sequence of “history” words (briefly alluded to in our filling-in- the-blank example in Section 3). Many of word (type) vector alogorithms already in use were based on a notion fixed-size context.

A full explanation of the differences in the learning algorithms, particularly the neural network architectures, is out of scope for this introduction, but it’s fair to say that the space of possible learners for contextual word vectors has not yet been fully explored;

* Day 62: SE
- *Title*：Neurological Divide: An fMRI Study of Prose and CodeWriting
- *Year*: 2020
- *Proc*: ICSE

The following content is referred from [2]
** Problem
Recent efforts have investigated the neural processes associated with reading and comprehending code — however, we lack a thorough understanding of the human cognitive processes underlying code writing.

** Method
They leverage functional brain imaging to investigate neural representations of code writing in comparison to prose writing.

They present the first human study in which participants wrote code and prose while undergoing a functional magnetic resonance imaging (fMRI) brain scan, making use of a full-sized fMRI-safe QWERTY keyboard.

** Result
They find that code writing and prose writing are significantly dissimilar neural tasks. While prose writing entails significant left hemisphere activity associated with language, code writing involves more activations of the right hemisphere, including regions associated with attention control, working memory, planning and spatial cognition. These findings are unlike existing work in which code and prose comprehension were studied. By contrast, we present
the first evidence suggesting that code and prose writing are quite dissimilar at the neural level.

** Future work
This unexpected result — that the production of code and prose rely on highly distinct cognitive substrates — though quite preliminary, paves the way forfuture investigations analogous to those based on medical imaging for prose writing. In addition to developing a foundational understanding of code writing, this empirical distinction may be leveraged to develop tools and pedagogies (e.g., transfer training), subsequently affecting large scale workforce retraining and educational reform. Moreover, neurological evidence that code and prose writing are not as intertwined as conventionally thought may encourage more diverse participation in computer science.

* Day 63: SE
- *Title*: Is Static Analysis Able to Identify Unnecessary Source Code?
- *Year*: 2020
- *Journal*: TOSEM

The following content is referred from [3]
** Problem
Grown software systems often contain code that is not necessary anymore. Such unnecessary code wastes resources during development and maintenance, for example, when preparing code for migration or certification. Running a profiler may reveal code that is not used in production, but it is often time-consuming to obtain representative data in this way.

** Method
We investigate to what extent a static analysis approach, which is based on code stability and code centrality, is able to identify unnecessary code and whether its recommendations are relevant in practice. To study the feasibility and usefulness of our approach, we conducted a study involving 14 open-source and closedsource software systems. As there is no perfect oracle for unnecessary code, we compared recommendations for unnecessary code with historical cleanups, runtime usage data, and feedback from 25 developers of five software projects

They implemented their approach as a recommender system to evaluate our work on 14 opensource and closed-source software systems.

** Result
The results suggest that static analysis can provide quick feedback on unnecessary code and is useful in practice.

** Future work
In thiswork, they focused on unnecessary code from a development andmaintenance perspective. It would be interesting to see whether similar approaches help test developers to focus their test effort on relevant parts of the software system.

* Day 64
- *Title*: Albert: A lite bert for self-supervised learning of language representations

- *Year*: 2019
- *Proc*: ICLR 2020

** Problem
Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times.

** Method
To address these problems, they present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT.

ALBERT incorporates two parameter reduction techniques that lift the major obstacles in scaling pre-trained models.
- The first one is a factorized embedding parameterization.
- The second technique is cross-layer parameter sharing.

They also introduce a self-supervised loss for sentence-order prediction (SOP). SOP primary focuses on inter-sentence coherence and is designed to address the ineffectiveness.

** Result
Comprehensive empirical evidence shows that their proposed methods lead to models that scale much better compared to the original BERT.

** Future Work
An important next step is thus to speed up the training and inference speed of ALBERT through methods like sparse attention and block attention.

* Day 65
- *Title*: A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects
- *Year*: 2020
- *Proc*: TSE

** Problem
The continuous contributions made by long time contributors (LTCs) are a key factor enabling open source software (OSS) projects to be successful and survival. We study GITHUB as it has a large number of OSS projects and millions of contributors, which enables the study of the transition from newcomers to LTCs. They investigate whether they can effectively predict newcomers in OSS projects to be LTCs based on their activity data that is collected from GITHUB.

** Method
They collect GITHUB data from GHTorrent, a mirror of GITHUB data. They select the most popular 917 projects, which contain 75,046 contributors. We determine a developer as a LTC of a project if the time interval between his/her ﬁrst and last commit in the project is larger than a certain time T. In the experiment, they use three different settings on the time interval: 1, 2, and 3 years. There are 9,238, 3,968, and 1,577 contributors who become LTCs of a project in three settings of time interval, respectively.

*** Evaluation metric
They use AUC, namely Area Under the receiver operating characteristic (ROC) Curve, to evaluate the effectiveness of the proposed prediction models. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) across all thresholds.

** Result
To build a prediction model, they extract many features from the activities of developers on GITHUB, which group into ﬁve dimensions: developer proﬁle, repository proﬁle, developer monthly activity, repository monthly activity, and collaboration network. They apply several classiﬁers including naive Bayes, SVM, decision tree, kNN and random forest. They ﬁnd that random forest classiﬁer achieves the best performance with AUCs of more than 0.75 in all three settings of time interval for LTCs. They also investigate the most important features that differentiate newcomers who become LTCs from newcomers who stay in the projects for a short time.

** Future work
In the future, they want to collect more developers’ activities in OSS projects and further validate the effectiveness of our approach using more developers and projects.

* Day 66
- *Title*: On the Generalizability of Neural Program Analyzers with respect to Semantic-Preserving Program Transformations
- *Year*: 2020

The following content is referred from [66]

** Problem
With the prevalence of publicly available source code repositories to train deep neural network models, neural program analyzers can do well in source code analysis tasks such as predicting method names in given programs that cannot be easily done by traditional program analyzers. lthough such analyzers have been tested on various existing datasets, the extent in which they generalize to unforeseen source code is largely unknown.

** Method
They propose to evaluate the generalizability of neural program analyzers with respect to semantic-preserving transformations: a generalizable neural program analyzer should perform equally well on programs that are of the same semantics but of different lexical appearances and syntactical structures.

- 3 Java datasets
- 3 neural network models for code: code2vec, code2seq, Gated Graph Neural Networks (GGNN)

nine neural program analyzers for Evaluation

** Result
Their results show that even with small semantically preserving changes to the programs, these neural program analyzers often fail to generalize their performance. Their results also suggest that neural program analyzers based on data and control dependencies in programs generalize better than neural program analyzers based only on abstract syntax trees. On the positive side, they observe that as the size of training dataset grows and diversifies the generalizability of correct predictions produced by the analyzers can be improved too.

** Future work
Future work that includes more semantic-preserving and even some semi-semantic-preserving transformations in the approach and adapts more fine-grained predication change metrics may further extend the applicability of their approach to various neural program analyzers designed for different tasks.

* Reference
1. Smith, N. A. (2019). Contextual word representations: A contextual introduction. arXiv preprint arXiv:1902.06006.

2. Krueger, R., Huang, Y., Liu, X., Santander, T., Weimer, W., & Leach, K. (2020). Neurological Divide: An fMRI Study of Prose and Code Writing. In 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE) (Vol. 13).

3. HAAS, R., NIEDERMAYR, R., ROEHM, T., & APEL, S. (2019). Is Static Analysis Able to Identify Unnecessary Source Code?. Transactions on Software Engineering and Methodology (TOSEM), 178.

4. Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., & Soricut, R. (2019). Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942.

5. Bao, L., Xia, X., Lo, D., & Murphy, G. C. (2019). A large scale study of long-time contributor prediction for GitHub projects. IEEE Transactions on Software Engineering.

6. Rabin, M., Islam, R., Bui, N. D., Yu, Y., Jiang, L., & Alipour, M. A. (2020). On the Generalizability of Neural Program Analyzers with respect to Semantic-Preserving Program Transformations. arXiv preprint arXiv:2008.01566.